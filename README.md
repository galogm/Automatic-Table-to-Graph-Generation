# AutoG

## Introduction

Recent years have witnessed significant advancements in graph machine learning (GML), with its applications spanning numerous domains. However, the focus of GML has predominantly been on developing powerful models, often overlooking a crucial initial step: constructing suitable graphs from common data formats, such as tabular data. This construction process is fundamental to applying graph-based models, yet it remains largely understudied and lacks formalization. Our research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated datasets to formalize and evaluate the effectiveness of graph construction methods, and 2. Existing automatic construction methods can only be applied to some specific cases, while tedious human engineering is required to generate high-quality graphs. To tackle these challenges, we present a two-fold contribution. First, we introduce a set of datasets to formalize and evaluate graph construction methods. Second, we propose an LLM-based solution, AutoG, automatically generating high-quality graph schemas without human intervention. The experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance, and AutoG can generate high-quality graphs that rival those produced by human experts.

## Environment preparation

First, install the 4dbinfer-related libraries

```
bash multi-table-benchmark/conda/create_conda_env.sh
```

Download deepjoin

```
git clone https://github.com/mutong184/deepjoin
```

Optional library for further development (we have cached the LLM outputs so you can omit these)

```
pip install llama-index-llms-bedrock
pip install llama-index
pip install valentine
```


## 1. Setup: Generate the pre-processing dataset

```
bash scripts/download.sh
```

This will generate datasets with two versions (old/expert).
Old is a trivial preprocessed version acting as a simple baseline (you can think of it the pre-processed version generated by some heuristic-based systems).
Expert is the version generated by human experts. 
We change the name of columns to get rid of trivial shortcuts.
The input of AutoG is the data file of ``old''. However, no schema information will be provided. 

## 2. Run Autog

Check `scripts/autog.sh`.

## 3. Run GML

Check `scripts/run.sh`.

## How to apply AutoG to your own dataset?

1. Use `analyze_dataframes` from `models.llm.gconstruct` to generate the metadata information of your data

2. Use `identify` in prompts to generate initial type guess

3. Wrap your data into a DBBRDBDataset

4. Use AutoG to generate first-round prompt

## Citation

```
@inproceedings{
chen2025autog,
title={AutoG: Towards automatic graph construction from tabular data},
author={Zhikai Chen and Han Xie and Jian Zhang and Xiang song and Jiliang Tang and Huzefa Rangwala and George Karypis},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=hovDbX4Gh6}
}
```




